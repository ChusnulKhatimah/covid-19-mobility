# -*- coding: utf-8 -*-
"""DSA - (ain't) rocket science.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T9JR97alNQ-DBeiroMcNq0bIs9RD52b0

# Import Dependencies
"""

# import libraries
import pandas as pd
from pandas import DataFrame
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn import preprocessing
import time
from datetime import datetime
from datetime import timedelta

from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error
from sklearn.metrics import median_absolute_error, mean_squared_error, mean_squared_log_error

def mean_absolute_percentage_error(y_true, y_pred):
  return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

!pip install pmdarima
from pmdarima.arima import auto_arima

# connect with google drive
from google.colab import drive
drive.mount('/content/drive')

"""# Read Dataset"""

# read covid-19 and mobility dataset
data_covid = pd.read_csv("/content/drive/MyDrive/COMPFEST.ID/Jakarta & Dunia/covid_19_data.csv/covid_19_data.csv")
data_mobility = pd.read_csv("/content/drive/MyDrive/COMPFEST.ID/Mobility/Global_Mobility_Report.csv")

"""# Understanding Data

## Data COVID-19

We retrieved COVID-19 data from Novel Corona Virus 2019 Dataset that is available on Kaggle (https://www.kaggle.com/datasets/sudalairajkumar/novel-corona-virus-2019-dataset).
"""

# look at top 5 of covid data
data_covid.head()

# look at row and column number of covid dataset
data_covid.shape

# rename column that uses "/" and " "
data_covid.rename(columns = {'Province/State':'Province', 'Country/Region':'Country', 'Last Update':'LastUpdate' }, inplace = True)

# look again at top 5 of covid dataset
data_covid.head()

# look at bottom 5 of covid dataset
data_covid.tail()

# look at null values and datatypes of covid dataset
data_covid.info()

# rename ObservationDate to date since we're going to merge 2 dataset, and merge it based on date
data_covid.rename(columns = {'ObservationDate':'date'}, inplace = True)

# convert ObservationDate and LastUpdate to datetime datatypes
data_covid["date"]=pd.to_datetime(data_covid["date"])
data_covid["LastUpdate"]=pd.to_datetime(data_covid["LastUpdate"])

# checking missing value
print("Jumlah missing value tiap kolom:", data_covid.isna().sum())

# filter Country that contains Indonesia
jakarta = (data_covid["Province"] == "DKI Jakarta")

# made a new dataset that only contains Indonesia as its Country
data_covid_jakarta = data_covid.loc[jakarta]

# look at top 5 of our new dataset that focusing in Indonesia Covid-19 case
data_covid_jakarta.head()

"""
drop Province, since we're going to focus in Indonesia,
and all Indonesia's province has null values, so better delete it.

drop SNo since it has no significance in our analysis.
"""
data_covid.drop("Province",1,inplace=True)
data_covid.drop("SNo",1,inplace=True)

# look again at our top 5 covid dataset
data_covid.head()

# look again at bottom 5 of our covid dataset
data_covid.tail()

"""### Made a new dataset focusing in Indonesia"""

# filter Country that contains Indonesia
indonesia = (data_covid["Country"] == "Indonesia")

# made a new dataset that only contains Indonesia as its Country
data_covid_indonesia = data_covid.loc[indonesia]

# look at top 5 of our new dataset that focusing in Indonesia Covid-19 case
data_covid_indonesia.head()

# look at bottom 5 of our new dataset that focusing in Indonesia Covid-19 case
data_covid_indonesia.tail()

# look at row and column number of Indonesia Covid-19 dataset
data_covid_indonesia.shape

"""## Data Mobility

We retrieved mobility data from the Google Community Mobility Report (CMR), where Google collected anonymized users' location history data. 


---

Later on, we will use daily aggregated mobility data in Indonesia from 2 March 2020 to 29 May 2021.

The descriptions of the places are as follows:
1. Retail and Recreational: mobility towards places such as restaurants, cafes, shopping
centers, museums, libraries, and picture theatres;
2. Grocery and Pharmacy:  mobility trends for places such as grocery shops, food warehouses, markets, local hats, farmerâ€™s markets, specialty food shops, different drug or
medicine stores, and pharmacies;
3. Parks: places of attraction including local parks, national parks, public beaches,
marinas, dog parks, plazas, and public gardens;
4. Transit stations: a process by which a person moves from one place to places like
public transport hubs such as subway, bus, and train stations;
5. Workplaces: the process of going to places of work from a home;
6. Residential mobility: mobility in the direction of places of residence where a person lived.
"""

# look at top 5 of mobility dataset
data_mobility.head()

# look at row and column number of mobility dataset
data_mobility.shape

# checking missing value
print("Jumlah missing value tiap kolom:\n",data_mobility.isna().sum())

"""
drop country_region_code since it has the same function with country_region,
drop sub_region_1 since we're just going to focus on country's
and so do on sub_region_2.
drop metro_area since it has almost 100% of null values.
drop iso_3166_2_code, census_fips_code, place_id since it hasn't give any significance to our analysis.
"""
data_mobility = data_mobility.drop('country_region_code', axis=1)
data_mobility = data_mobility.drop('sub_region_2', axis=1)
data_mobility = data_mobility.drop('metro_area', axis=1)
data_mobility = data_mobility.drop('iso_3166_2_code', axis=1)
data_mobility = data_mobility.drop('census_fips_code', axis=1)
data_mobility = data_mobility.drop('place_id', axis=1)

"""
fill columns that hass null values with their median values
"""
data_mobility["retail_and_recreation_percent_change_from_baseline"] = data_mobility["retail_and_recreation_percent_change_from_baseline"].fillna(data_mobility["retail_and_recreation_percent_change_from_baseline"].median()) # Median
data_mobility["grocery_and_pharmacy_percent_change_from_baseline"] = data_mobility["grocery_and_pharmacy_percent_change_from_baseline"].fillna(data_mobility["grocery_and_pharmacy_percent_change_from_baseline"].median())
data_mobility["parks_percent_change_from_baseline"] = data_mobility["parks_percent_change_from_baseline"].fillna(data_mobility["parks_percent_change_from_baseline"].median())
data_mobility["transit_stations_percent_change_from_baseline"] = data_mobility["transit_stations_percent_change_from_baseline"].fillna(data_mobility["transit_stations_percent_change_from_baseline"].median())
data_mobility["workplaces_percent_change_from_baseline"] = data_mobility["workplaces_percent_change_from_baseline"].fillna(data_mobility["workplaces_percent_change_from_baseline"].median())
data_mobility["residential_percent_change_from_baseline"] = data_mobility["residential_percent_change_from_baseline"].fillna(data_mobility["residential_percent_change_from_baseline"].median())

# checking missing value
print("Jumlah missing value tiap kolom:\n",data_mobility.isna().sum())

# checking mobility dataset datatypes
data_mobility.info()

# convert date on mobility datset into datetime datatypes
data_mobility['date'] =  pd.to_datetime(data_mobility['date'])

# check again mobility dataset datatypes
data_mobility.info()

# rename country_region since we're going to merge 2 dataset, and merge it based on country's name
data_mobility.rename(columns = {'country_region':'Country'}, inplace = True)

# set date to become mobility dataset index
data_mobility = data_mobility.set_index("date")

# look at top 5 of mobility dataset
data_mobility.head()

# look at bottom 5 of mobility dataset
data_mobility.tail()

"""Since, we're going to merge two dataset(data_covid_indonesia & data_mobility_indonesia),then both of it, should have same date so all the data could correlate to each other.
So, when each dataset starts and end?
*   data_covid_indonesia
start: 2020-03-02
end: 2021-05-29
*   data_mobility_indonesia
start: 2020-02-15
end: 2021-05-29 
NEXT, to merge it all, we needed date that is 'inner join'
---
Because data_mobility_indonesia started early rather than data_covid_indonesia, data_mobility_indonesia will be changed into just like data_covid_indonesia date started.
So, data_mobility_indonesia then again will be set on:
*   start: 2020-03-02
*   end: 2021-05-29





"""

data_mobility = data_mobility['2020-03-02' :'2021-05-29']

# look at row and column number of mobility dataset
data_mobility.shape

"""### Made a new dataset focusing in Indonesia"""

# define mobility that Indonesia as it's only country
indonesia_mobility = (data_mobility["Country"] == "Indonesia")

# new dataset of mobility in indonesia
data_mobility_indonesia = data_mobility.loc[indonesia_mobility]

# look at top 5 of indonesia mobility dataset
data_mobility_indonesia.head()

# look at bottom 5 of indonesia mobility dataset
data_mobility_indonesia.tail()

# look at row and column number of indonesia mobility dataset
data_mobility_indonesia.shape

"""## Dataset Indonesia (COVID & Mobility)"""

# define new dataset that merging indonesia's covid and mobility data
dataset = pd.merge(data_covid_indonesia, data_mobility_indonesia.reset_index(), on=["date","Country"], how="inner").set_index("date")

# look at top 5 of this merged dataset
dataset.head()

# look at bottom 5 of this newly merged dataset
dataset.tail()

# look at row and column number of this newly merged dataset
dataset.shape

# check duplicate index
dataset[dataset.index.duplicated()]

# groupby index (date) and sum variables that needed to be sum
dataset = dataset.groupby(dataset.index).agg({'Country': 'first',
                                              'LastUpdate': 'last',
                                              'Confirmed':sum, 
                                              'Deaths':sum,
                                              'Recovered':sum,
                                              'retail_and_recreation_percent_change_from_baseline':sum,
                                              'grocery_and_pharmacy_percent_change_from_baseline':sum,
                                              'parks_percent_change_from_baseline':sum,
                                              'transit_stations_percent_change_from_baseline':sum,
                                              'workplaces_percent_change_from_baseline':sum,
                                              'residential_percent_change_from_baseline':sum})

dataset

dataset.shape

"""# Exploratory Data Analysis

## Types of Cases

There are 3 types of cases in COVID-19:

1.   Confirmed Cases.
If one tested positive, then it is considered as a Confirmed Cases.
2.   Probable Cases.
A probable COVID-19 case could mean one of two things:
*   It is likely that you had a COVID-19 infection
*   It is likely that you have a current COVID-19 infection but it hasn't been confirmed through test(s).
3.   Active Cases.
People that is currently infected. It is case that minus people who have been recovered and deaths.
4.   Closed Cases.
If one had recovered from COVID-19 or if one had died.

### Active Cases
"""

# active cases
dataset["active_cases"] = dataset["Confirmed"] - dataset["Recovered"] - dataset["Deaths"]

"""An increasing in the number of Active Cases could mean two things:
*   Increasing on Recovered Cases
*   Decreasing on Deaths

### Closed Cases
"""

# closed cases
dataset["closed_cases"] = dataset["Recovered"] + dataset["Deaths"]

"""An increasing in the number of Closed Cases could mean either:
*   Increasing on Recovered Cases; 
or
*   Increasing on Deaths

## Fatality Ratio

Fatality Ratio is the ratio of people who's gone because of COVID-19.

Fatality Ratio is when you divide number of deaths (Deaths) and number of confirmed cases (Confirmed).
"""

# fatality ratio
dataset["fatality_ratio"] = (dataset["Deaths"] / dataset["Confirmed"])

"""Fatality Ratio is affected by preparedness/access and the ability of healthcare workers to carry out examinations.

## Recovery Ratio

Recovery Ratio is important to determine a country's development towards controlling coronavirus.
"""

# recovery ratio
dataset["recovery_ratio"] = (dataset["Recovered"] / dataset["Confirmed"])

"""Recovery Ratio is the ratio of people who had recovered from COVID-19.

## Comparative of Each Cases
"""

# made a new dataset from existing dataset focusing on each column
confirmed = dataset['Confirmed'].reset_index()
deaths = dataset["Deaths"].reset_index()
recovered = dataset["Recovered"].reset_index()
active = dataset["active_cases"].reset_index()
closed = dataset["closed_cases"].reset_index()
fatality = dataset["fatality_ratio"].reset_index()
recovery = dataset["recovery_ratio"].reset_index()

# define fig
fig = go.Figure()

# made a plot for Confirmed Cases in Indonesia
fig.add_trace(go.Scatter(x=confirmed["date"],
                         y=confirmed["Confirmed"],
                         mode="lines+markers",
                         name="Confirmed Cases",
                         line=dict(color="blue", width=1)
))

# made a plot for Death Cases in Indonesia
fig.add_trace(go.Scatter(x=deaths["date"],
                         y=deaths["Deaths"],
                         mode="lines+markers",
                         name="Death Cases",
                         line=dict(color="red", width=1)
))

# made a plot for Recovered Cases in Indonesia
fig.add_trace(go.Scatter(x=recovered["date"],
                         y=recovered["Recovered"],
                         mode="lines+markers",
                         name="Recovered Cases",
                         line=dict(color="green", width=1)
))

# made a plot for Active Cases in Indonesia
fig.add_trace(go.Scatter(x=active["date"],
                         y=active["active_cases"],
                         mode="lines+markers",
                         name="Active Cases",
                         line=dict(color="yellow", width=1)
))

# made a plot for Closed Cases in Indonesia
fig.add_trace(go.Scatter(x=closed["date"],
                         y=closed["closed_cases"],
                         mode="lines+markers",
                         name="Closed Cases",
                         line=dict(color="black", width=1)
))

# update whole layout of figure
fig.update_layout(
    title="Indonesia Corona Virus Cases",
    xaxis_tickfont_size=13,
    yaxis=dict(
        title="Number of Cases",
        titlefont_size=17,
        tickfont_size=13,
    ),
    legend=dict(
        x=0,
        y=1.0,
        bgcolor="rgba(255, 255, 255, 0)",
        bordercolor="rgba(255, 255, 255, 0)"
    )
)
fig.show()

# define fig
fig1 = go.Figure()

# made a plot for Fatality Ratio in Indonesia
fig1.add_trace(go.Scatter(x=fatality["date"],
                         y=fatality["fatality_ratio"],
                         mode="lines+markers",
                         name="Fatality Ratio",
                         line=dict(color="orange", width=1)
))

# made a plot for Recovery Ratio in Indonesia
fig1.add_trace(go.Scatter(x=recovery["date"],
                         y=recovery["recovery_ratio"],
                         mode="lines+markers",
                         name="Recovery Ratio",
                         line=dict(color="light blue", width=1)
))

# update whole layout of figure
fig1.update_layout(
    title="Indonesia Fatality and Recovery Ratio of COVID-19 Cases",
    xaxis_tickfont_size=13,
    yaxis=dict(
        title="Ratio",
        titlefont_size=17,
        tickfont_size=13,
    ),
    legend=dict(
        x=0,
        y=1.0,
        bgcolor="rgba(255, 255, 255, 0)",
        bordercolor="rgba(255, 255, 255, 0)"
    )
)
fig1.show()

# made a new dataset from existing dataset focusing on each column focusing on mobility
retails_and_recreations = dataset["retail_and_recreation_percent_change_from_baseline"].reset_index()
grocery_and_pharmacy = dataset["grocery_and_pharmacy_percent_change_from_baseline"].reset_index()
parks = dataset["parks_percent_change_from_baseline"].reset_index()
transit_stations = dataset["transit_stations_percent_change_from_baseline"].reset_index()
workplaces = dataset["workplaces_percent_change_from_baseline"].reset_index()
residential = dataset["residential_percent_change_from_baseline"].reset_index()

"""## Retails and Recreations & Active Cases"""

# top 5 of retail and recreation mobility
retails_and_recreations.head()

# made a scatter plot of retail and recreation mobility and active cases in indonesia
plt.scatter(retails_and_recreations["retail_and_recreation_percent_change_from_baseline"],
            active["active_cases"])
plt.xlabel('Retail and Recreations Mobility')
plt.ylabel('Active Cases')
plt.title('Scatter Plot Retail and Recreations Mobility & Active Cases in Indonesia')
plt.show()

"""## Grocery and Pharmacy & Active Cases"""

# top 5 of grocery and pharmacy mobility dataset
grocery_and_pharmacy.head()

# made a scatter plot of grocery and pharmacy mobility and active cases in indonesia
plt.scatter(grocery_and_pharmacy["grocery_and_pharmacy_percent_change_from_baseline"],
            active["active_cases"])
plt.xlabel('Grocery and Pharmacy Mobility')
plt.ylabel('Active Cases')
plt.title('Scatter Plot Grocery and Pharmacy Mobility & Active Cases in Indonesia')
plt.show()

"""## Parks & Active Cases"""

# top 5 of parks mobility dataset
parks.head()

# made a scatter plot of parks mobility and active cases in indonesia
plt.scatter(parks["parks_percent_change_from_baseline"],
            active["active_cases"])
plt.xlabel('Parks Mobility')
plt.ylabel('Active Cases')
plt.title('Scatter Plot Parks Mobility & Active Cases in Indonesia')
plt.show()

"""## Transit Stations & Active Cases"""

# top 5 of transit stations mobility dataset
transit_stations.head()

# made a scatter plot of transit stations mobility and active cases in indonesia
plt.scatter(transit_stations["transit_stations_percent_change_from_baseline"],
            active["active_cases"])
plt.xlabel('Transit Stations Mobility')
plt.ylabel('Active Cases')
plt.title('Scatter Plot Transit Stations Mobility & Active Cases in Indonesia')
plt.show()

"""## Workplaces & Active Cases"""

# top 5 of workplaces mobility dataset
workplaces.head()

# made a scatter plot of workplaces mobility and active cases in indonesia
plt.scatter(workplaces["workplaces_percent_change_from_baseline"],
            active["active_cases"])
plt.xlabel('Workplaces Mobility')
plt.ylabel('Active Cases')
plt.title('Scatter Plot Workplaces Mobility & Active Cases in Indonesia')
plt.show()

"""## Residential & Active Cases"""

# top 5 of residential mobility dataset
residential.head()

# made a scatter plot of residential mobility and active cases in indonesia
plt.scatter(residential["residential_percent_change_from_baseline"],
            active["active_cases"])
plt.xlabel('Residential Mobility')
plt.ylabel('Active Cases')
plt.title('Scatter Plot Residential Mobility & Active Cases in Indonesia')
plt.show()

"""# Linear Regression Modelling"""

# define linear regression model
lr_model = LinearRegression()

"""## Retail and Recreation Mobility & Active Cases"""

# define predictor and response variables
X, y = dataset[["retail_and_recreation_percent_change_from_baseline"]], dataset.active_cases

# fit regression model
lr_model.fit(X, y)

# calculate R-Squared of Regression Model
r_squared = lr_model.score(X, y)

# view R-Squared values
print(r_squared)

"""## Grocery and Pharmacy Mobility & Active Cases"""

# define predictor and response variables
X, y = dataset[["grocery_and_pharmacy_percent_change_from_baseline"]], dataset.active_cases

# fit regression model
lr_model.fit(X, y)

# calculate R-Squared of Regression Model
r_squared = lr_model.score(X, y)

# view R-Squared values
print(r_squared)

"""## Parks Mobility & Active Cases"""

# define predictor and response variables
X, y = dataset[["parks_percent_change_from_baseline"]], dataset.active_cases

# fit regression model
lr_model.fit(X, y)

# calculate R-Squared of Regression Model
r_squared = lr_model.score(X, y)

# view R-Squared values
print(r_squared)

"""## Transit Stations Mobility & Active Cases"""

# define predictor and response variables
X, y = dataset[["transit_stations_percent_change_from_baseline"]], dataset.active_cases

# fit regression model
lr_model.fit(X, y)

# calculate R-Squared of Regression Model
r_squared = lr_model.score(X, y)

# view R-Squared values
print(r_squared)

"""## Workplaces Mobility & Active Cases"""

# define predictor and response variables
X, y = dataset[["workplaces_percent_change_from_baseline"]], dataset.active_cases

# fit regression model
lr_model.fit(X, y)

# calculate R-Squared of Regression Model
r_squared = lr_model.score(X, y)

# view R-Squared values
print(r_squared)

"""## Residential Mobility & Active Cases"""

# define predictor and response variables
X, y = dataset[["residential_percent_change_from_baseline"]], dataset.active_cases

# fit regression model
lr_model.fit(X, y)

# calculate R-Squared of Regression Model
r_squared = lr_model.score(X, y)

# view R-Squared values
print(r_squared)

"""# FBProphet Modelling"""

# import fbprophet library
from fbprophet import Prophet

# define fbprophet model
model = Prophet(interval_width=0.95,weekly_seasonality=True,)

# set X and y or 'ds' and 'y' for forecasting
prophet_confirmed=pd.DataFrame(zip(list(dataset.index),list(dataset["Confirmed"])),columns=['ds','y'])

# fit dataset
model.fit(prophet_confirmed)

# made a forecast for 17 days ahead
forecast_c=model.make_future_dataframe(periods=17)
forecast_confirmed=forecast_c.copy()

# predict forecast for 17 days ahead
confirmed_forecast=model.predict(forecast_c)
print(confirmed_forecast[['ds','yhat', 'yhat_lower', 'yhat_upper']])

# plot forecast 
print(model.plot(confirmed_forecast))

# plot component of forecast
print(model.plot_components(confirmed_forecast))

# dataframe that extends into future 12 months
future_dates = model.make_future_dataframe(periods = 3, freq='M')
print('First week to forecast.')
future_dates.tail()

# predictions
forecast = model.predict(future_dates)

# predictions for last week
forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(7)

fc = forecast[['ds', 'yhat']].rename(columns = {'Date': 'ds', 'Forecast': 'yhat'})
fc.head()

# visualizing predictions
sales_forecast = model.plot(forecast);

model.plot_components(forecast)

"""# Conclusion

1. Retail and Recreational: mobility towards places such as restaurants, cafes, shopping
centers, museums, libraries, and picture theatres;
2. Grocery and Pharmacy:  mobility trends for places such as grocery shops, food warehouses, markets, local hats, farmerâ€™s markets, specialty food shops, different drug or
medicine stores, and pharmacies;
3. Parks: places of attraction including local parks, national parks, public beaches,
marinas, dog parks, plazas, and public gardens;
4. Transit stations: a process by which a person moves from one place to places like
public transport hubs such as subway, bus, and train stations;
5. Workplaces: the process of going to places of work from a home;
6. Residential mobility: mobility in the direction of places of residence where a person lived.

**Effect of Mobility by Categories on COVID-19 Dynamics in Indonesia:**


---

Based on R2 of each category of mobility in Indonesia and its active cases:
1. Retail and Recreations: 0.085 
2. Grocery and Pharmacy: 0.186
3. Parks: 0.042
4. Transit Stations: 0.145
5. Workplaces: 0.064
6. Residential: 0.414

Mobility on **Residential** have the highest correlation with number of COVID-19 cases. Subsequently, 
* Grocery and Pharmacy
* Transit Stations
* Retail and Recreations
* Workplaces
* Parks

Groceries and Pharmacy correlated on the increasing of COVID-19 new cases, because during pandemic, traditional markets, modern markets, and drugstore are essentials for strive during pandemic, so there's no restrictions, and all business in this category are still allowed to be open. Other than that, mostly traditional market tend to be crowded and unorganized.

Transit Stations correlated on the increasing number of COVID-19 cases since the increasing number of passenger during public holidays, religious day/event, make the visits to transit stations within the city increased. Also, confined spaces and closed environments on public transportations have a high risk of infectious disease transmission, since it potentially leads to crowding.

Workplaces doesn't have a significant correlation since some of workers required to work from office, but eventhough required to work from office, the compliance on health protocol, such as mask wearing, temperature check, and washing hands.

Parks has the lowest correlation with COVID-19 since it's an open space, and tend not to be as crowded as other category. And the air circulation is much better in open space, therefore the probability of infectious disease to transferred to others is low.

**Based on future forecasting using FBProphet:**
The number of confirmed cases in Indonesia will show an increasing number for 17 days ahead, and also for 3 months ahead.

Decision makers in public health could utilize the current analysis to anticipate increased COVID-19 cases, especially during seasonal events, such as annual religious holidays or other long holidays.

From this analysis, we have some recommendations for policy maker:
1. Control new cases and new clusters and prevent community transmission by rapidly **finding and isolating all cases**, **providing the infected one with appropriate care**, and **tracing**, **quarantining**, and supporting all contacts.
2. Suppress community transmission through **infection prevention** and **control measures**, population level **physical distancing measures**, and appropriate and proportionate **restrictions** or **non-essential domestic and international travels**.
3. Reduce **mortality rate** by **providing appropriate clinical care** for those affected by COVID-19, ensuring the **continuity of essential health and social services**, and **protecting frontline workers and vulnerable populations**.
"""